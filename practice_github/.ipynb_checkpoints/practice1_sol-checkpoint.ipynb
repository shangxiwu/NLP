{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the occurrence of character in file \"sample.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:7\n",
      "AIR:2\n",
      "AN:3\n",
      "AND:3\n",
      "AT:2\n",
      "DEVICE:2\n",
      "FLIGHT:2\n",
      "FROM:2\n",
      "GAGEY:2\n",
      "IN:3\n",
      "OF:3\n",
      "ON:2\n",
      "PLANE:2\n",
      "SAID:2\n",
      "THAT:2\n",
      "THE:11\n",
      "TO:3\n",
      "TOILET:2\n",
      "WAS:5\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "fp = open(\"./dataset/sample.txt\", \"r\")\n",
    "article = fp.read()\n",
    "new_article = re.sub(\"[^a-zA-Z\\s]\", \"\", article)\n",
    "words = new_article.split()\n",
    "word_counts = {}\n",
    "\n",
    "for word in words:\n",
    "    if word.upper() in word_counts:\n",
    "        word_counts[word.upper()] = word_counts[word.upper()] + 1\n",
    "    else:\n",
    "        word_counts[word.upper()] = 1\n",
    "\n",
    "key_list = list(word_counts.keys())\n",
    "key_list.sort()\n",
    "for key in key_list:\n",
    "    if word_counts[key] > 1:\n",
    "        print(\"{}:{}\".format(key, word_counts[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort words in the file \"sample.txt\" and give each word a unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'Air': 1, 'All': 2, 'CEO': 3, 'France': 4, 'Frances': 5, 'Frederic': 6, 'Gagey': 7, 'He': 8, 'Indian': 9, 'Kenyan': 10, 'Mauritius': 11, 'Mombasa': 12, 'Mr': 13, 'Ocean': 14, 'Paris': 15, 'Sunday': 16, 'The': 17, 'There': 18, 'They': 19, 'a': 20, 'added': 21, 'airport': 22, 'alarm': 23, 'alerted': 24, 'an': 25, 'and': 26, 'at': 27, 'available': 28, 'bomb': 29, 'capable': 30, 'cardboard': 31, 'caused': 32, 'city': 33, 'creating': 34, 'damaging': 35, 'decided': 36, 'device': 37, 'during': 38, 'emergency': 39, 'explosion': 40, 'false': 41, 'flight': 42, 'flying': 43, 'found': 44, 'from': 45, 'harmless': 46, 'in': 47, 'indicates': 48, 'information': 49, 'island': 50, 'it': 51, 'kitchen': 52, 'landing': 53, 'made': 54, 'make': 55, 'moment': 56, 'nearest': 57, 'not': 58, 'object': 59, 'of': 60, 'on': 61, 'or': 62, 'paper': 63, 'passenger': 64, 'pilot': 65, 'plane': 66, 'point': 67, 'port': 68, 'probably': 69, 'put': 70, 'said': 71, 'scare': 72, 'some': 73, 'someone': 74, 'staff': 75, 'strangelooking': 76, 'that': 77, 'the': 78, 'timer': 79, 'to': 80, 'toilet': 81, 'us': 82, 'was': 83, 'which': 84}\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "fp = open(\"./dataset/sample.txt\", \"r\")\n",
    "article = fp.read()\n",
    "new_article = re.sub(\"[^a-zA-Z\\s]\", \"\", article)\n",
    "\n",
    "words = new_article.split()\n",
    "words_list = []\n",
    "\n",
    "for word in words:\n",
    "    words_list.append(word)\n",
    "\n",
    "\n",
    "words_unique_list = list(set(words_list))\n",
    "words_unique_list = sorted(words_unique_list)\n",
    "\n",
    "words_dict = {}\n",
    "for index, word in enumerate(words_unique_list):\n",
    "    words_dict[word] = index\n",
    "\n",
    "print(words_dict)\n",
    "#print(words_dict['Air'])\n",
    "print(len(words_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Above result to create one-hot encode vector on word \"Air\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def onehot(index, n_class):\n",
    "    '''Get one-hot encoding '''\n",
    "    return np.eye(n_class)[index]\n",
    "\n",
    "print(onehot(words_dict['Air'], len(words_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
