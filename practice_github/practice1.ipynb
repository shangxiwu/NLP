{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change character to uppercase and find the occurrence of character in file \"sample.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'AIR',\n",
       " 'AIR',\n",
       " 'ALL',\n",
       " 'CEO',\n",
       " 'FRANCE',\n",
       " 'FRANCES',\n",
       " 'FREDERIC',\n",
       " 'GAGEY',\n",
       " 'GAGEY',\n",
       " 'HE',\n",
       " 'INDIAN',\n",
       " 'KENYAN',\n",
       " 'MAURITIUS',\n",
       " 'MOMBASA',\n",
       " 'MR',\n",
       " 'OCEAN',\n",
       " 'PARIS',\n",
       " 'SUNDAY',\n",
       " 'THE',\n",
       " 'THERE',\n",
       " 'THEY',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'ADDED',\n",
       " 'AIRPORT',\n",
       " 'ALARM',\n",
       " 'ALERTED',\n",
       " 'AN',\n",
       " 'AN',\n",
       " 'AN',\n",
       " 'AND',\n",
       " 'AND',\n",
       " 'AND',\n",
       " 'AT',\n",
       " 'AT',\n",
       " 'AVAILABLE',\n",
       " 'BOMB',\n",
       " 'CAPABLE',\n",
       " 'CARDBOARD',\n",
       " 'CAUSED',\n",
       " 'CITY',\n",
       " 'CREATING',\n",
       " 'DAMAGING',\n",
       " 'DECIDED',\n",
       " 'DEVICE',\n",
       " 'DEVICE',\n",
       " 'DURING',\n",
       " 'EMERGENCY',\n",
       " 'EXPLOSION',\n",
       " 'FALSE',\n",
       " 'FLIGHT',\n",
       " 'FLIGHT',\n",
       " 'FLYING',\n",
       " 'FOUND',\n",
       " 'FROM',\n",
       " 'FROM',\n",
       " 'HARMLESS',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'INDICATES',\n",
       " 'INFORMATION',\n",
       " 'ISLAND',\n",
       " 'IT',\n",
       " 'KITCHEN',\n",
       " 'LANDING',\n",
       " 'MADE',\n",
       " 'MAKE',\n",
       " 'MOMENT',\n",
       " 'NEAREST',\n",
       " 'NOT',\n",
       " 'OBJECT',\n",
       " 'OF',\n",
       " 'OF',\n",
       " 'OF',\n",
       " 'ON',\n",
       " 'ON',\n",
       " 'OR',\n",
       " 'PAPER',\n",
       " 'PASSENGER',\n",
       " 'PILOT',\n",
       " 'PLANE',\n",
       " 'PLANE',\n",
       " 'POINT',\n",
       " 'PORT',\n",
       " 'PROBABLY',\n",
       " 'PUT',\n",
       " 'SAID',\n",
       " 'SAID',\n",
       " 'SCARE',\n",
       " 'SOME',\n",
       " 'SOMEONE',\n",
       " 'STAFF',\n",
       " 'STRANGELOOKING',\n",
       " 'THAT',\n",
       " 'THAT',\n",
       " 'THE',\n",
       " 'THE',\n",
       " 'THE',\n",
       " 'THE',\n",
       " 'THE',\n",
       " 'THE',\n",
       " 'THE',\n",
       " 'THE',\n",
       " 'THE',\n",
       " 'THE',\n",
       " 'TIMER',\n",
       " 'TO',\n",
       " 'TO',\n",
       " 'TO',\n",
       " 'TOILET',\n",
       " 'TOILET',\n",
       " 'US',\n",
       " 'WAS',\n",
       " 'WAS',\n",
       " 'WAS',\n",
       " 'WAS',\n",
       " 'WAS',\n",
       " 'WHICH']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "fp = open(\"./dataset/sample.txt\", \"r\")\n",
    "article = fp.read()\n",
    "new_article = re.sub(\"[^a-zA-Z\\s]\", \"\", article)\n",
    "words = new_article.split()\n",
    "word_counts = {}\n",
    "\n",
    "words.sort()\n",
    "\n",
    "word = list(enumerate(words))\n",
    "\n",
    "li = []\n",
    "for i, seq in word:\n",
    "    li.append(seq.upper()) \n",
    "    i += 0\n",
    "li\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:7\n",
      "AIR:2\n",
      "AN:3\n",
      "AND:3\n",
      "AT:2\n",
      "DEVICE:2\n",
      "FLIGHT:2\n",
      "FROM:2\n",
      "GAGEY:2\n",
      "IN:3\n",
      "OF:3\n",
      "ON:2\n",
      "PLANE:2\n",
      "SAID:2\n",
      "THAT:2\n",
      "THE:11\n",
      "TO:3\n",
      "TOILET:2\n",
      "WAS:5\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "fp = open(\"./dataset/sample.txt\", \"r\")\n",
    "article = fp.read()\n",
    "new_article = re.sub(\"[^a-zA-Z\\s]\", \"\", article)\n",
    "words = new_article.split()\n",
    "word_counts = {}\n",
    "\n",
    "### write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort words in the file \"sample.txt\" and give each word a unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'Air': 1, 'All': 2, 'CEO': 3, 'France': 4, 'Frances': 5, 'Frederic': 6, 'Gagey': 7, 'He': 8, 'Indian': 9, 'Kenyan': 10, 'Mauritius': 11, 'Mombasa': 12, 'Mr': 13, 'Ocean': 14, 'Paris': 15, 'Sunday': 16, 'The': 17, 'There': 18, 'They': 19, 'a': 20, 'added': 21, 'airport': 22, 'alarm': 23, 'alerted': 24, 'an': 25, 'and': 26, 'at': 27, 'available': 28, 'bomb': 29, 'capable': 30, 'cardboard': 31, 'caused': 32, 'city': 33, 'creating': 34, 'damaging': 35, 'decided': 36, 'device': 37, 'during': 38, 'emergency': 39, 'explosion': 40, 'false': 41, 'flight': 42, 'flying': 43, 'found': 44, 'from': 45, 'harmless': 46, 'in': 47, 'indicates': 48, 'information': 49, 'island': 50, 'it': 51, 'kitchen': 52, 'landing': 53, 'made': 54, 'make': 55, 'moment': 56, 'nearest': 57, 'not': 58, 'object': 59, 'of': 60, 'on': 61, 'or': 62, 'paper': 63, 'passenger': 64, 'pilot': 65, 'plane': 66, 'point': 67, 'port': 68, 'probably': 69, 'put': 70, 'said': 71, 'scare': 72, 'some': 73, 'someone': 74, 'staff': 75, 'strangelooking': 76, 'that': 77, 'the': 78, 'timer': 79, 'to': 80, 'toilet': 81, 'us': 82, 'was': 83, 'which': 84}\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "fp = open(\"./dataset/sample.txt\", \"r\")\n",
    "article = fp.read()\n",
    "new_article = re.sub(\"[^a-zA-Z\\s]\", \"\", article)\n",
    "\n",
    "words = new_article.split()\n",
    "\n",
    "# write your code here\n",
    "\n",
    "print(words_dict)\n",
    "#print(words_dict['Air'])\n",
    "print(len(words_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Above result to create one-hot encode vector on word \"Air\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def onehot(index, n_class):\n",
    "    # write your code here\n",
    "\n",
    "print(onehot(words_dict['Air'], len(words_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
